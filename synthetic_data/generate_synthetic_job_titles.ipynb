{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either hard code your path to the project, or set it as an environment variable\n",
    "# build_project_path = os.environ['BUILD_PROJECT_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_path = os.path.join(build_project_path, 'synthetic_data')\n",
    "data_path = os.path.join(synthetic_data_path, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if synthetic_data_path not in sys.path:\n",
    "    sys.path.append(synthetic_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_requests import generate_prompt\n",
    "\n",
    "seed_titles_df = pd.read_csv(os.path.join(data_path, 'seed_titles.csv'))\n",
    "\n",
    "seed_titles = seed_titles_df['seed_title'].unique()\n",
    "\n",
    "example_seed_titles = np.random.choice(seed_titles, 5)\n",
    "\n",
    "example_prompt = generate_prompt(example_seed_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Experiment with different models and see how they compare!</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Meta-Llama-3.3-70B-Instruct'\n",
    "# model_name = 'Meta-Llama-3.1-405B-Instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_requests import get_client\n",
    "\n",
    "client = get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_requests import async_make_api_call\n",
    "\n",
    "example_response = await async_make_api_call(client, model_name, example_prompt, perturbation_std=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_parsing import parse_gpt_response\n",
    "\n",
    "parsed_output = parse_gpt_response(example_response.choices[0].message.content, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed_title, response in zip(example_seed_titles, parsed_output):\n",
    "    print(f'Variations of: {seed_title}:')\n",
    "    print('-------------------')\n",
    "    for i, variation in enumerate(response):\n",
    "        print(f'{i+1}: {variation}')\n",
    "\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_requests import async_main_stubborn\n",
    "\n",
    "output_dict_path = os.path.join(data_path, 'jitter_responses.pkl')\n",
    "response_dict = await async_main_stubborn(\n",
    "    all_query_titles=seed_titles,\n",
    "    client=client,\n",
    "    model_name=model_name,\n",
    "    output_path=output_dict_path,\n",
    "    chunk_size=5,\n",
    "    num_examples_per_title=5,\n",
    "    giveup_after=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "output_dict_path = os.path.join(data_path, 'jitter_responses.pkl')\n",
    "\n",
    "with open(output_dict_path, 'rb') as f:\n",
    "    response_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_df = {\n",
    "    'jittered_title': [],\n",
    "    'seed_title': [],\n",
    "}\n",
    "\n",
    "for seed_title, jittered_titles in response_dict.items():\n",
    "    for jittered_title in jittered_titles:\n",
    "        jitter_df['jittered_title'].append(jittered_title)\n",
    "        jitter_df['seed_title'].append(seed_title)\n",
    "\n",
    "jitter_df = pd.DataFrame(jitter_df)\n",
    "\n",
    "jitter_df = jitter_df.merge(seed_titles_df, on='seed_title', how='left')\n",
    "jitter_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_df.to_csv(os.path.join(data_path, 'jittered_titles.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".build-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
